{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c342187",
   "metadata": {},
   "source": [
    ">Base Clients : \"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/Clients.csv\"\n",
    ">\n",
    ">Base Produits : \"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/Products.csv\"\n",
    ">\n",
    ">Logs : \"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/transactions.logs\"\n",
    ">\n",
    ">What is the aim of the exercise?\n",
    ">\n",
    "> => We want to build an ETL tool using pandas.\n",
    ">\n",
    ">  1. We extract data.\n",
    ">\n",
    ">  2. We're going to transform it so that we can analyze it. Our analysis will focus on transactions and customers. **For example, we could try to identify the next transaction date by customer: Machine Learning objective)**.\n",
    ">    - Identify the join key.\n",
    ">    - Perform the join.\n",
    ">    - Restructure data, Feature Engineering, etc.\n",
    ">      - How many days before the current transaction? \"DaysUntilNextTransaction\"\n",
    ">      - How many transactions before the current transaction? \"NumberOfPastTransactions\"\n",
    ">      - On which day of the week is the transaction carried out? \"TransactionWeekDay\"\n",
    ">      - On what date is the transaction carried out? \"TransactionDay\"\n",
    ">      - How many transactions per day? \"NumberOfTransactionsThisDay\"\n",
    ">    - Keep only the variables that will be used.\n",
    ">\n",
    ">  3. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fdc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5397d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the following dataframes: df_product, df_client, df_transaction\n",
    "# For df_transaction : \n",
    "# - remember to change the date from object to date\n",
    "# - column names are: \"TransactionID\", \"Date\", \"ClientID\", \"ProductID\", \"Quantity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60010ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client = pd.read_csv(\"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/Clients.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.read_csv(\"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/Products.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction = pd.read_csv(\"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/transactions.logs\",\n",
    "        sep=\"---\",\n",
    "        engine='python',\n",
    "        names=[\"TransactionID\", \"Date\", \"ClientID\", \"ProductID\", \"Quantity\"],\n",
    "        parse_dates=[\"Date\"],\n",
    "        index_col=0,\n",
    "        nrows=100)\n",
    "display(df_transaction.head(3), df_transaction.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3fcac",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791989d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of an extract() function that creates and returns the 3 dataframes\n",
    "\n",
    "def extract():\n",
    "    df_transaction = pd.read_csv(\"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/transactions.logs\",\n",
    "            sep='---',\n",
    "            header=None,\n",
    "            engine='python',\n",
    "            names=[\"TransactionID\", \"Date\", \"ClientID\", \"ProductID\", \"Quantity\"],\n",
    "            nrows=2000,\n",
    "            parse_dates=[\"Date\"],\n",
    "            index_col=0\n",
    "           )\n",
    "    df_client = pd.read_csv(\"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/Clients.csv\", index_col=0)\n",
    "    df_product = pd.read_csv(\"https://assets-datascientest.s3.eu-west-1.amazonaws.com/mc_intro_de/Products.csv\", index_col=0)\n",
    "    return df_client, df_product, df_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ecc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes using extract()\n",
    "df_client, df_product, df_transaction = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the display() method to get an overview of your dataframes\n",
    "display(df_client.head(5), df_product.head(5), df_transaction.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fcad4a",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the 3 dataframes together\n",
    "\n",
    "df = df_transaction.merge(df_client, on=\"ClientID\", how=\"left\").merge(df_product, on=\"ProductID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424971a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order lines per client and date\n",
    "\n",
    "df = df.sort_values([\"ClientID\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff70448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DayUntilNextTransactions column : go check pandas.Series.shift() and pandas.Series.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27706a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DayUntilNextTransactions\"] = (df.groupby(\"ClientID\")[\"Date\"].shift(-1) - df[\"Date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f931a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the NumberOfPastTransactions column : go check cumcount()\n",
    "df[\"NumberOfPastTransactions\"] = df.groupby(\"ClientID\").cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a34e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TransactionWeekDay column : go check weekday\n",
    "df[\"TransactionWeekDay\"] = df[\"Date\"].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the transaction date without the hour in a TransactionDay column\n",
    "df[\"TransactionDay\"] = df[\"Date\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the NumberOfTransactionsPerDay column : go check cumcount()\n",
    "df[\"NumberOfTransactionsPerDay\"] = df.groupby([\"ClientID\", \"TransactionDay\"]).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the useless columns : ClientName, ClientAddress, ClientCity, ClientZipCode,\n",
    "# ProductName, ClientState and TransactionDay\n",
    "\n",
    "df.drop(columns=[\"ClientName\", \"ClientAddress\", \"ClientCity\", \"ClientZipCode\", \"ProductName\", \"ClientState\", \"TransactionDay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963558c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete lines with null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named transform(df_client, df_product, df_transaction) which transforms the 3 dataframes\n",
    "# and returns the final dataframe\n",
    "\n",
    "def transform(df_client, df_product, df_transaction):\n",
    "\n",
    "    # mergez les 3 dataframes\n",
    "    df = df_transaction.merge(df_client, on=\"ClientID\", how=\"left\").merge(df_product, on=\"ProductID\", how=\"left\")\n",
    "\n",
    "    # ordonnez les lignes par Client et par date\n",
    "    df = df.sort_values(by=[\"ClientID\", \"Date\"])\n",
    "    \n",
    "    # Créez la colonne DayUntilNextTransactions : allez voir pandas.Series.shift() et pandas.Series.dt\n",
    "    df[\"DayUntilNextTransactions\"] = (df[\"Date\"] - df.groupby(\"ClientID\")[\"Date\"].shift(1)).dt.days\n",
    "\n",
    "    # Créez la colonne NumberOfPastTransactions : allez voir cumcount()\n",
    "    df[\"NumberOfPastTransactions\"] = df.groupby(\"ClientID\").cumcount()\n",
    "    \n",
    "    # Récuperez le jour de la transaction sans l'heure\n",
    "    df[\"TransactionDay\"] = df[\"Date\"].dt.date\n",
    "\n",
    "    # Créez la colonne TransactionWeekDay : allez voir weekday\n",
    "    df[\"TransactionWeekDay\"] = df[\"Date\"].dt.weekday\n",
    "\n",
    "    # Créez la colonne NumberOfTransactionsPerDay : allez voir cumcount()\n",
    "    df[\"NumberOfTransactionsPerDay\"] = df.groupby([\"ClientID\", \"TransactionDay\"]).cumcount()\n",
    "\n",
    "    # Supprimez les colonnes inutiles\n",
    "    df = df.drop(columns=[\"ClientName\", \"ClientAddress\", \"ClientCity\", \"ClientZipCode\", \"ProductName\", \"ClientState\"])\n",
    "\n",
    "    # Supprimez les lignes avec des valeurs null\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99769d6f",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a load(df) function that saves the dataframe in a file named analyze_<today_date>.csv\n",
    "# Remember to import the necessary library\n",
    "def load(df):\n",
    "    today_str = datetime.strftime(datetime.today(), \"%Y-%m-%d\")\n",
    "    filename = \"analyse\" + today_str + \".csv\"\n",
    "    df.to_csv(filename, index=True, index_label='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(transform(*extract()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
